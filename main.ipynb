{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf=pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              text            tag\n",
       "0  将 军 百 战 死 <end>  B I B I S END"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>将 军 百 战 死 &lt;end&gt;</td>\n      <td>B I B I S END</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "myDf[\"text\"]=myDf[\"text\"].apply(lambda x:x+\" <end>\")\n",
    "myDf[\"tag\"]=myDf[\"tag\"].apply(lambda x:x+\" END\")\n",
    "myDf[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data to one-hot embedding to generalize X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordIndexDict={\"<pad>\":0}\n",
    "wi=1\n",
    "for row in myDf[\"text\"].values.tolist():\n",
    "    if type(row)==float:\n",
    "        print(row)\n",
    "        break\n",
    "    for word in row.split(\" \"):\n",
    "        if word not in wordIndexDict:\n",
    "            wordIndexDict[word]=wi\n",
    "            wi+=1\n",
    "vocabSize=wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen=max(len(row) for row in myDf[\"text\"].values.tolist())\n",
    "sequenceLengths=[len(row) for row in myDf[\"text\"].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf[\"text\"]=myDf[\"text\"].apply(lambda x:[wordIndexDict[word] for word in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0],\n",
       "       [ 1,  2,  7,  8,  9,  4, 10,  6,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0],\n",
       "       [ 1,  1,  2,  8,  9,  4, 11,  6,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0],\n",
       "       [ 2,  4,  1,  2,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0],\n",
       "       [ 1,  2,  4,  1,  2,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0],\n",
       "       [ 1,  2,  4,  1,  2,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "X=tf.keras.preprocessing.sequence.pad_sequences(myDf[\"text\"],\n",
    "                                                value=wordIndexDict[\"<pad>\"],\n",
    "                                                padding='post',\n",
    "                                                maxlen=maxLen)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizing Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import re\n",
    "\n",
    "myDf[\"tag\"]=myDf[\"tag\"].apply(lambda x:re.sub(\"\\-\\S+\",\"\",x))\n",
    "\n",
    "tagIndexDict = {\"PAD\": 0}\n",
    "ti = 1\n",
    "for row in tqdm.tqdm(myDf[\"tag\"].values.tolist()):\n",
    "    for tag in row.split(\" \"):\n",
    "        if tag not in tagIndexDict:\n",
    "            tagIndexDict[tag] = ti\n",
    "            ti += 1\n",
    "tagSum = len(list(tagIndexDict.keys()))\n",
    "myDf[\"tag\"] = myDf[\"tag\"].apply(lambda x:x.split()+[\"PAD\" for i in range(maxLen-len(x.split()))])\n",
    "myDf[\"tag\"] = myDf[\"tag\"].apply(lambda x:[tagIndexDict[tagItem] for tagItem in x])\n",
    "# myDf[\"tag\"] = myDf[\"tag\"].apply(lambda x: [[0 if tagI != tagIndexDict[tagItem] else 1\n",
    "#                                             for tagI in range(len(tagIndexDict))]\n",
    "#                                             for tagItem in x])\n",
    "y=np.array(myDf[\"tag\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6, 19)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y.shape # it is OK whether y is one-hot embedding or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiLSTMCRF import MyBiLSTMCRF\n",
    "myModel=MyBiLSTMCRF(vocabSize,maxLen, tagIndexDict,tagSum,sequenceLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 19, 100)           1200      \n_________________________________________________________________\nbidirectional (Bidirectional (None, 19, 5)             4240      \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 19, 5)             440       \n_________________________________________________________________\ncrf_layer (CRF)              (None, 19)                65        \n=================================================================\nTotal params: 5,945\nTrainable params: 5,945\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myModel.myBiLSTMCRF.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "oss: 0.2603\n",
      "Epoch 1260/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2602\n",
      "Epoch 1261/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2602\n",
      "Epoch 1262/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2601\n",
      "Epoch 1263/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2601\n",
      "Epoch 1264/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2601\n",
      "Epoch 1265/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2600\n",
      "Epoch 1266/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2600\n",
      "Epoch 1267/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2600\n",
      "Epoch 1268/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2599\n",
      "Epoch 1269/1500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2599\n",
      "Epoch 1270/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2598\n",
      "Epoch 1271/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2598\n",
      "Epoch 1272/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2598\n",
      "Epoch 1273/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2597\n",
      "Epoch 1274/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2597\n",
      "Epoch 1275/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2596\n",
      "Epoch 1276/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2596\n",
      "Epoch 1277/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2596\n",
      "Epoch 1278/1500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2595\n",
      "Epoch 1279/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2595\n",
      "Epoch 1280/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2595\n",
      "Epoch 1281/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2594\n",
      "Epoch 1282/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2594\n",
      "Epoch 1283/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2593\n",
      "Epoch 1284/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2593\n",
      "Epoch 1285/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2593\n",
      "Epoch 1286/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2592\n",
      "Epoch 1287/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2592\n",
      "Epoch 1288/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2592\n",
      "Epoch 1289/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2592\n",
      "Epoch 1290/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2591\n",
      "Epoch 1291/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2591\n",
      "Epoch 1292/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2591\n",
      "Epoch 1293/1500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2591\n",
      "Epoch 1294/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2592\n",
      "Epoch 1295/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2594\n",
      "Epoch 1296/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2599\n",
      "Epoch 1297/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2600\n",
      "Epoch 1298/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2604\n",
      "Epoch 1299/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2593\n",
      "Epoch 1300/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2588\n",
      "Epoch 1301/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2590\n",
      "Epoch 1302/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2592\n",
      "Epoch 1303/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2589\n",
      "Epoch 1304/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2587\n",
      "Epoch 1305/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2589\n",
      "Epoch 1306/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2589\n",
      "Epoch 1307/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2586\n",
      "Epoch 1308/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2587\n",
      "Epoch 1309/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2588\n",
      "Epoch 1310/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2584\n",
      "Epoch 1311/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2586\n",
      "Epoch 1312/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2587\n",
      "Epoch 1313/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2583\n",
      "Epoch 1314/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2584\n",
      "Epoch 1315/1500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2586\n",
      "Epoch 1316/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2582\n",
      "Epoch 1317/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2583\n",
      "Epoch 1318/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2583\n",
      "Epoch 1319/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2581\n",
      "Epoch 1320/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2583\n",
      "Epoch 1321/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2582\n",
      "Epoch 1322/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2581\n",
      "Epoch 1323/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2582\n",
      "Epoch 1324/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2580\n",
      "Epoch 1325/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2580\n",
      "Epoch 1326/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2581\n",
      "Epoch 1327/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2579\n",
      "Epoch 1328/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2579\n",
      "Epoch 1329/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2579\n",
      "Epoch 1330/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2577\n",
      "Epoch 1331/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2578\n",
      "Epoch 1332/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2578\n",
      "Epoch 1333/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2576\n",
      "Epoch 1334/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2576\n",
      "Epoch 1335/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2576\n",
      "Epoch 1336/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2575\n",
      "Epoch 1337/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2575\n",
      "Epoch 1338/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2575\n",
      "Epoch 1339/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2574\n",
      "Epoch 1340/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2575\n",
      "Epoch 1341/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2574\n",
      "Epoch 1342/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2574\n",
      "Epoch 1343/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2573\n",
      "Epoch 1344/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2573\n",
      "Epoch 1345/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2573\n",
      "Epoch 1346/1500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2572\n",
      "Epoch 1347/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2572\n",
      "Epoch 1348/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2572\n",
      "Epoch 1349/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2571\n",
      "Epoch 1350/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2571\n",
      "Epoch 1351/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2571\n",
      "Epoch 1352/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2570\n",
      "Epoch 1353/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2570\n",
      "Epoch 1354/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2570\n",
      "Epoch 1355/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2570\n",
      "Epoch 1356/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2569\n",
      "Epoch 1357/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2569\n",
      "Epoch 1358/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2568\n",
      "Epoch 1359/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2568\n",
      "Epoch 1360/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2568\n",
      "Epoch 1361/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2567\n",
      "Epoch 1362/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2567\n",
      "Epoch 1363/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2567\n",
      "Epoch 1364/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2567\n",
      "Epoch 1365/1500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2567\n",
      "Epoch 1366/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2566\n",
      "Epoch 1367/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2566\n",
      "Epoch 1368/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2565\n",
      "Epoch 1369/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2565\n",
      "Epoch 1370/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2565\n",
      "Epoch 1371/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2564\n",
      "Epoch 1372/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2564\n",
      "Epoch 1373/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2564\n",
      "Epoch 1374/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2564\n",
      "Epoch 1375/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2563\n",
      "Epoch 1376/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2563\n",
      "Epoch 1377/1500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2562\n",
      "Epoch 1378/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2562\n",
      "Epoch 1379/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2562\n",
      "Epoch 1380/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2562\n",
      "Epoch 1381/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2561\n",
      "Epoch 1382/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2561\n",
      "Epoch 1383/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2561\n",
      "Epoch 1384/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2561\n",
      "Epoch 1385/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2560\n",
      "Epoch 1386/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2560\n",
      "Epoch 1387/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2560\n",
      "Epoch 1388/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2559\n",
      "Epoch 1389/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2559\n",
      "Epoch 1390/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2559\n",
      "Epoch 1391/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2558\n",
      "Epoch 1392/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2558\n",
      "Epoch 1393/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2558\n",
      "Epoch 1394/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2557\n",
      "Epoch 1395/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2557\n",
      "Epoch 1396/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2557\n",
      "Epoch 1397/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2557\n",
      "Epoch 1398/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2557\n",
      "Epoch 1399/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2556\n",
      "Epoch 1400/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2556\n",
      "Epoch 1401/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2556\n",
      "Epoch 1402/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2556\n",
      "Epoch 1403/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2555\n",
      "Epoch 1404/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2556\n",
      "Epoch 1405/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2557\n",
      "Epoch 1406/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2559\n",
      "Epoch 1407/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2561\n",
      "Epoch 1408/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2567\n",
      "Epoch 1409/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2563\n",
      "Epoch 1410/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2559\n",
      "Epoch 1411/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2553\n",
      "Epoch 1412/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2555\n",
      "Epoch 1413/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2558\n",
      "Epoch 1414/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2554\n",
      "Epoch 1415/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2552\n",
      "Epoch 1416/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2554\n",
      "Epoch 1417/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2553\n",
      "Epoch 1418/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2551\n",
      "Epoch 1419/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2552\n",
      "Epoch 1420/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2552\n",
      "Epoch 1421/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2550\n",
      "Epoch 1422/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2550\n",
      "Epoch 1423/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2551\n",
      "Epoch 1424/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2550\n",
      "Epoch 1425/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2549\n",
      "Epoch 1426/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2549\n",
      "Epoch 1427/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2549\n",
      "Epoch 1428/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2549\n",
      "Epoch 1429/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2548\n",
      "Epoch 1430/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2548\n",
      "Epoch 1431/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2548\n",
      "Epoch 1432/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2547\n",
      "Epoch 1433/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2547\n",
      "Epoch 1434/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2547\n",
      "Epoch 1435/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2546\n",
      "Epoch 1436/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2546\n",
      "Epoch 1437/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2546\n",
      "Epoch 1438/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2545\n",
      "Epoch 1439/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2545\n",
      "Epoch 1440/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2545\n",
      "Epoch 1441/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2545\n",
      "Epoch 1442/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2544\n",
      "Epoch 1443/1500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2544\n",
      "Epoch 1444/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2544\n",
      "Epoch 1445/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2544\n",
      "Epoch 1446/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2543\n",
      "Epoch 1447/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2543\n",
      "Epoch 1448/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2543\n",
      "Epoch 1449/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2542\n",
      "Epoch 1450/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2542\n",
      "Epoch 1451/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2542\n",
      "Epoch 1452/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2542\n",
      "Epoch 1453/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2541\n",
      "Epoch 1454/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2541\n",
      "Epoch 1455/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2541\n",
      "Epoch 1456/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2541\n",
      "Epoch 1457/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2540\n",
      "Epoch 1458/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2540\n",
      "Epoch 1459/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2540\n",
      "Epoch 1460/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2540\n",
      "Epoch 1461/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2539\n",
      "Epoch 1462/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2539\n",
      "Epoch 1463/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2539\n",
      "Epoch 1464/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2539\n",
      "Epoch 1465/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2538\n",
      "Epoch 1466/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2538\n",
      "Epoch 1467/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2538\n",
      "Epoch 1468/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2538\n",
      "Epoch 1469/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2537\n",
      "Epoch 1470/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2537\n",
      "Epoch 1471/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2537\n",
      "Epoch 1472/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2536\n",
      "Epoch 1473/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2536\n",
      "Epoch 1474/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2536\n",
      "Epoch 1475/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2536\n",
      "Epoch 1476/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2535\n",
      "Epoch 1477/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2535\n",
      "Epoch 1478/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2535\n",
      "Epoch 1479/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2535\n",
      "Epoch 1480/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2534\n",
      "Epoch 1481/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2534\n",
      "Epoch 1482/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2534\n",
      "Epoch 1483/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2534\n",
      "Epoch 1484/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2534\n",
      "Epoch 1485/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2533\n",
      "Epoch 1486/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2533\n",
      "Epoch 1487/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2533\n",
      "Epoch 1488/1500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2533\n",
      "Epoch 1489/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2534\n",
      "Epoch 1490/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2535\n",
      "Epoch 1491/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2538\n",
      "Epoch 1492/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2539\n",
      "Epoch 1493/1500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2542\n",
      "Epoch 1494/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2536\n",
      "Epoch 1495/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2532\n",
      "Epoch 1496/1500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2531\n",
      "Epoch 1497/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2533\n",
      "Epoch 1498/1500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2534\n",
      "Epoch 1499/1500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2531\n",
      "Epoch 1500/1500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2530\n"
     ]
    }
   ],
   "source": [
    "history=myModel.fit(X,y,epochs=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testI=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preY=myModel.predict(X)[testI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "将 将 军 带 上 战 车\nS B I B I B I\n"
     ]
    }
   ],
   "source": [
    "indexTagDict=dict(list(zip(list(tagIndexDict.values()),list(tagIndexDict.keys()))))\n",
    "indexWordDict=dict(list(zip(list(wordIndexDict.values()),list(wordIndexDict.keys()))))\n",
    "\n",
    "sentenceList=[indexWordDict[wordItem] for wordItem in X[testI]]\n",
    "sentenceList=sentenceList[:sentenceList.index(\"<end>\")]\n",
    "\n",
    "tagList=[indexTagDict[tagItem] for tagItem in preY]\n",
    "tagList=tagList[:tagList.index(\"END\")]\n",
    "\n",
    "print(\" \".join(sentenceList))\n",
    "print(\" \".join(tagList))"
   ]
  }
 ]
}